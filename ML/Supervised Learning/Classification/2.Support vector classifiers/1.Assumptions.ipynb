{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b98a0be",
   "metadata": {},
   "source": [
    "# ðŸ”¹ Assumptions in Support Vector Classifier (SVC)\n",
    "\n",
    "### 1. **Data is (approximately) separable**\n",
    "\n",
    "* In **hard margin SVC**, the assumption is that the data is **perfectly linearly separable**.\n",
    "* In **soft margin SVC**, the assumption relaxes â†’ data may overlap a little, but an approximate separating hyperplane still exists.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Classes are well-defined**\n",
    "\n",
    "* SVC assumes that the data points can be assigned to distinct classes.\n",
    "* Works best when classes are **not heavily overlapping**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Maximum-margin principle holds**\n",
    "\n",
    "* The algorithm assumes that the **decision boundary that maximizes the margin** between classes is the best one (leads to better generalization).\n",
    "* This is why support vectors (points closest to the boundary) are critical.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Kernel choice reflects data structure**\n",
    "\n",
    "* If classes are **linearly separable**, a **linear kernel** is enough.\n",
    "* If not, we assume that mapping to a **higher-dimensional space** (via kernel trick like RBF, polynomial, sigmoid) will make them separable.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Feature scaling is important**\n",
    "\n",
    "* SVC assumes that features are on a **comparable scale** (since distance/margin depends on dot products).\n",
    "* Example: If one feature is in kilometers and another in millimeters, the model gets biased unless we normalize/standardize.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **No strong distributional assumptions**\n",
    "\n",
    "* Unlike logistic regression, SVC does **not assume a specific distribution** (normality, homoscedasticity, etc.).\n",
    "* It is **non-parametric** and only assumes that separating boundaries exist.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Binary classification (extendable)**\n",
    "\n",
    "* Originally designed for **binary classification**.\n",
    "* For multi-class problems, SVC assumes the problem can be broken into **One-vs-One (OvO)** or **One-vs-Rest (OvR)** strategies.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **In summary**:\n",
    "SVC assumes data can be (at least approximately) separated by a margin, features are scaled properly, and the chosen kernel captures the underlying structure. It makes far fewer statistical assumptions compared to regression models.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
