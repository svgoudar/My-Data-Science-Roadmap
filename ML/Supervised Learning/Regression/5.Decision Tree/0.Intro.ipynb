{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8404c594",
   "metadata": {},
   "source": [
    "### **Introduction to Decision Trees**\n",
    "\n",
    "Welcome! So far, we've covered several algorithms with their in-depth math and intuitions. Today, we're diving into **Decision Tree Algorithms**, one of the most important algorithms in machine learning. Decision trees are foundational because many advanced ensemble techniques, like **Random Forests** and **Boosting** methods, are built on top of them.\n",
    "\n",
    "---\n",
    "\n",
    "### **Decision Trees: Basics and Use Cases**\n",
    "\n",
    "A decision tree can solve both **classification** and **regression** problems. For this video, we’ll focus on **classification problems**. Along the way, we’ll discuss concepts like:\n",
    "\n",
    "- **Entropy**\n",
    "- **Gini Index**\n",
    "- **Information Gain**\n",
    "\n",
    "We’ll also briefly differentiate between the two major types of decision tree algorithms:\n",
    "\n",
    "1. **ID3 (Iterative Dichotomiser 3):** Allows multiple splits at a node.\n",
    "2. **CART (Classification and Regression Tree):** Restricts splits to binary decisions (used in libraries like `sklearn`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Intuition: Decision Trees as Conditional Statements**\n",
    "\n",
    "Think of decision trees as an extension of simple conditional statements. For example, in Python:\n",
    "\n",
    "```python\n",
    "age = 14\n",
    "if age <= 14:\n",
    "    print(\"The person is in school.\")\n",
    "elif 15 <= age <= 21:\n",
    "    print(\"The person may be in college.\")\n",
    "else:\n",
    "    print(\"The person has passed college.\")\n",
    "```\n",
    "\n",
    "This logic resembles how a decision tree splits data:\n",
    "\n",
    "1. Start with a **root node** (e.g., `age <= 14`).\n",
    "2. Branch into outcomes (e.g., **Yes** or **No**).\n",
    "3. Continue splitting based on new conditions until reaching a pure classification (e.g., \"School,\" \"College\").\n",
    "\n",
    "---\n",
    "\n",
    "### **Constructing a Decision Tree**\n",
    "\n",
    "Let’s explore how a decision tree is built using a **real-world dataset**. Imagine a dataset with these features:\n",
    "\n",
    "- **Outlook** (Sunny, Overcast, Rainy)\n",
    "- **Temperature**\n",
    "- **Humidity**\n",
    "- **Wind**\n",
    "Our goal: Predict whether someone will **Play Tennis**.\n",
    "\n",
    "#### Step 1: Selecting the Root Node\n",
    "\n",
    "- Start by evaluating each feature. For instance, take **Outlook**.\n",
    "- Count the occurrences:\n",
    "  - **Sunny:** 2 Yes, 3 No\n",
    "  - **Overcast:** 4 Yes, 0 No (Pure split)\n",
    "  - **Rainy:** 3 Yes, 2 No\n",
    "- Notice that **Sunny** and **Rainy** are **impure splits** (contain both Yes and No), while **Overcast** is a **pure split**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Metrics for Splitting**\n",
    "\n",
    "When splitting nodes, we use metrics like:\n",
    "\n",
    "1. **Entropy:** Measures the impurity in the dataset.\n",
    "2. **Information Gain:** Determines how much uncertainty is reduced after a split.\n",
    "3. **Gini Index:** Another measure of impurity, often used in CART.\n",
    "\n",
    "#### Example: Calculating Entropy\n",
    "\n",
    "For the root node:\n",
    "$\n",
    "\\text{Entropy} = - \\sum_{i=1}^{n} p_i \\cdot \\log_2(p_i)\n",
    "$\n",
    "Where$ p_i$ is the proportion of each class (Yes/No).\n",
    "\n",
    "#### Example: Information Gain\n",
    "\n",
    "$\n",
    "\\text{Information Gain} = \\text{Entropy (Parent)} - \\text{Weighted Average Entropy (Child Nodes)}\n",
    "$\n",
    "\n",
    "---\n",
    "\n",
    "### **Splitting Impure Nodes**\n",
    "\n",
    "For impure splits like **Sunny (2 Yes, 3 No)**:\n",
    "\n",
    "1. Consider another feature (e.g., **Temperature**).\n",
    "2. Split further until achieving pure nodes or acceptable impurity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion and Next Steps**\n",
    "\n",
    "This process continues until:\n",
    "\n",
    "- The tree reaches pure splits.\n",
    "- Or further splits don’t improve the model significantly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f4d75",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
