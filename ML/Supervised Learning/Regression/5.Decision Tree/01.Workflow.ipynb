{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e32fb4",
   "metadata": {},
   "source": [
    "# ⚡ Workflow of Decision Tree\n",
    "\n",
    "A **Decision Tree** splits the dataset into smaller and smaller subsets based on feature conditions until it reaches a stopping rule.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 1: Start with Dataset\n",
    "\n",
    "* Begin with the full dataset containing features $X$ and target $y$.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 2: Select the Best Split\n",
    "\n",
    "* For each feature, test possible split points.\n",
    "* Compute a **split criterion** (depends on problem type):\n",
    "\n",
    "  * **Classification**: Gini Impurity, Entropy (Information Gain).\n",
    "  * **Regression**: Variance reduction / Mean Squared Error (MSE).\n",
    "* Choose the feature and threshold that give the **best impurity reduction**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 3: Partition the Data\n",
    "\n",
    "* Split the dataset into two (or more) subsets based on the chosen rule.\n",
    "* Example: If feature = “Age < 30”, split into **Yes** and **No** groups.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 4: Repeat Recursively\n",
    "\n",
    "* For each subset, repeat **Step 2** and **Step 3**.\n",
    "* Grow child nodes (branches) until:\n",
    "\n",
    "  * Node is pure (all samples belong to one class).\n",
    "  * Maximum depth is reached.\n",
    "  * Minimum number of samples per node is reached.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 5: Assign Leaf Nodes\n",
    "\n",
    "* Each final node (leaf) represents a prediction:\n",
    "\n",
    "  * **Classification**: The majority class in that node.\n",
    "  * **Regression**: The average target value in that node.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Step 6: Make Predictions\n",
    "\n",
    "* For a new input:\n",
    "\n",
    "  * Start at the root.\n",
    "  * Follow the feature-based conditions down the tree.\n",
    "  * End at a leaf node → return prediction.\n",
    "\n",
    "---\n",
    "\n",
    "# 🚀 Intuition\n",
    "\n",
    "* The tree works like a **series of if–else questions**.\n",
    "* Each split **reduces uncertainty** (entropy, gini, or variance).\n",
    "* The final path leads to the prediction.\n",
    "\n",
    "---\n",
    "\n",
    "✅ In short:\n",
    "Dataset → Best Split (feature + threshold) → Recursive Partitioning → Leaf Node → Prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f957b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
