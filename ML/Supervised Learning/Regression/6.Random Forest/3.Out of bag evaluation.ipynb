{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d468abc",
   "metadata": {},
   "source": [
    "# ðŸŒ² Out-of-Bag (OOB) Evaluation\n",
    "\n",
    "## 1. Why OOB?\n",
    "\n",
    "When building each tree in a Random Forest, we use **bootstrap sampling**:\n",
    "\n",
    "* We sample $N$ data points *with replacement* from the training set of size $N$.\n",
    "* On average, about **63%** of the training samples get included in the bootstrap sample.\n",
    "* The remaining **37%** are **not used** for training that tree â€” these are called **Out-of-Bag (OOB) samples**.\n",
    "\n",
    "These OOB samples can act like a **test set** for that tree.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How it works mathematically\n",
    "\n",
    "Let training set = $\\{(x_i, y_i)\\}_{i=1}^N$.\n",
    "For each tree $t$:\n",
    "\n",
    "* $B_t$ = bootstrap sample used to train tree $t$.\n",
    "* $OOB_t$ = data points not in $B_t$.\n",
    "\n",
    "Now:\n",
    "\n",
    "* For each data point $x_i$, collect predictions only from the trees where $x_i \\in OOB_t$.\n",
    "* Aggregate those predictions:\n",
    "\n",
    "For **classification**:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i^{OOB} = \\arg\\max_{c} \\sum_{t: x_i \\in OOB_t} \\mathbb{1}(\\hat{y}_t(x_i) = c)\n",
    "$$\n",
    "\n",
    "For **regression**:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i^{OOB} = \\frac{1}{|T_i|} \\sum_{t: x_i \\in OOB_t} \\hat{y}_t(x_i)\n",
    "$$\n",
    "\n",
    "where $T_i = \\{t : x_i \\in OOB_t\\}$.\n",
    "\n",
    "Then compute the overall **OOB error**:\n",
    "\n",
    "$$\n",
    "OOB\\ Error = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}(\\hat{y}_i^{OOB} \\neq y_i)\n",
    "$$\n",
    "\n",
    "(for classification, replace with MSE for regression).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Key Insights\n",
    "\n",
    "* **No separate validation set needed** â€” OOB acts like cross-validation.\n",
    "* OOB error is an **unbiased estimator** of test error.\n",
    "* Saves computation since it reuses the training process.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Example Intuition\n",
    "\n",
    "Imagine 100 trees:\n",
    "\n",
    "* Each sample is OOB in about 37 trees (on average).\n",
    "* Those trees act like mini test predictors for that sample.\n",
    "* At the end, youâ€™ve tested every point multiple times **without ever using it in training** for those trees.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Summary**:\n",
    "OOB evaluation is like having a **free built-in cross-validation** in Random Forests. It uses the \\~37% of data not seen by each tree to estimate performance, making Random Forest efficient and self-validating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1893e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
