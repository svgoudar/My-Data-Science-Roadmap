{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe9a618",
   "metadata": {},
   "source": [
    "# âš¡ Random Forest Workflow\n",
    "\n",
    "Random Forest is an **ensemble of decision trees** built using **Bagging + Random Feature Selection**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 1: Prepare the Dataset\n",
    "\n",
    "* Start with the original dataset with $N$ samples and $p$ features.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 2: Bootstrap Sampling\n",
    "\n",
    "* Create $B$ different training sets by sampling from the original dataset **with replacement** (bootstrap).\n",
    "* Each tree gets a slightly different dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 3: Grow Decision Trees\n",
    "\n",
    "* For each bootstrap sample, grow a decision tree using the following rules:\n",
    "\n",
    "  1. At each split, **randomly select a subset of features** (say $m < p$).\n",
    "  2. Choose the best feature from this subset using a split criterion (e.g., **Gini impurity** or **Entropy**).\n",
    "  3. Repeat until stopping criteria (like max depth, min samples per leaf) are met.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 4: Build the Forest\n",
    "\n",
    "* Repeat Step 2 and Step 3 for $B$ trees.\n",
    "* Each tree is **independent** of the others.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 5: Make Predictions\n",
    "\n",
    "* For **classification**:\n",
    "\n",
    "  $$\n",
    "  \\hat{y} = \\text{majority vote}\\{h_1(x), h_2(x), \\dots, h_B(x)\\}\n",
    "  $$\n",
    "* For **regression**:\n",
    "\n",
    "  $$\n",
    "  \\hat{y} = \\frac{1}{B}\\sum_{b=1}^B h_b(x)\n",
    "  $$\n",
    "\n",
    "\n",
    "### ðŸ”¹ Components\n",
    "\n",
    "* $\\hat{y}$ â†’ final prediction for input $x$.\n",
    "* $B$ â†’ total number of base models (e.g., number of decision trees).\n",
    "* $h_b(x)$ â†’ prediction from the $b$-th model (tree).\n",
    "* $\\frac{1}{B}\\sum_{b=1}^B$ â†’ average across all model predictions.\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Step 6: Evaluate Model (Optional)\n",
    "\n",
    "* Use **Out-of-Bag (OOB) samples** (data not included in a treeâ€™s bootstrap sample) for validation.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸš€ Intuition\n",
    "\n",
    "* **Bagging** reduces variance by averaging over many trees.\n",
    "* **Random feature selection** ensures trees are diverse (reduces correlation).\n",
    "* Together, Random Forest provides **high accuracy and robustness**.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… In short:\n",
    "Dataset â†’ Bootstrap samples â†’ Randomized trees â†’ Ensemble (voting/averaging) â†’ Final prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb93ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
