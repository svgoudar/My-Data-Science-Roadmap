{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564b01b7",
   "metadata": {},
   "source": [
    "### **1. Similarity Assumption**\n",
    "\n",
    "> **Points that are close to each other in feature space are likely to have similar outputs.**\n",
    "\n",
    "* KNN relies entirely on the notion of “closeness” (distance).\n",
    "* If nearby points have very different labels, KNN will perform poorly.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Feature Relevance**\n",
    "\n",
    "> **All features contribute equally and independently to the distance metric.**\n",
    "\n",
    "* KNN assumes the features are meaningful and properly scaled.\n",
    "* Irrelevant features or features with larger numerical ranges can dominate the distance calculation.\n",
    "* **Normalization or standardization** is usually required.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Local Stationarity**\n",
    "\n",
    "> **The decision boundary can be approximated locally.**\n",
    "\n",
    "* KNN assumes that within a small neighborhood around a point, the data behaves consistently.\n",
    "* This is why small K focuses on local patterns, while large K smooths over the global trend.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Non-parametric Assumption**\n",
    "\n",
    "> **KNN doesn’t assume any particular underlying data distribution.**\n",
    "\n",
    "* This is actually a “freedom” more than a strict assumption: it assumes you have enough data points to represent the local neighborhood accurately.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Data Sufficiency**\n",
    "\n",
    "> **Enough data is available to find meaningful neighbors.**\n",
    "\n",
    "* Sparse datasets can make neighborhoods unreliable.\n",
    "* Performance improves as the number of training samples increases, especially in high-dimensional spaces.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Noise Sensitivity**\n",
    "\n",
    "> **KNN assumes that neighbors are mostly correct and not noisy.**\n",
    "\n",
    "* Outliers or mislabeled points in the training data can mislead predictions, especially with small K.\n",
    "\n",
    "---\n",
    "\n",
    "💡 **Summary:**\n",
    "KNN works well if **similar points have similar labels, features are relevant and scaled, enough data is available, and noise is limited.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d41fc9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
