{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60160094",
   "metadata": {},
   "source": [
    "## **1. What is Ridge Regression?**\n",
    "\n",
    "Ridge is a type of **regularized linear regression** that adds an **L2 penalty** (squared magnitude of coefficients) to the loss function.\n",
    "\n",
    "* It helps control **overfitting** by shrinking coefficients.\n",
    "* Unlike Lasso, Ridge does **not set coefficients to zero** â†’ all features are kept but with smaller weights.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. The L2 Regularization Formula**\n",
    "\n",
    "Ordinary Least Squares (OLS) minimizes:\n",
    "\n",
    "$$\n",
    "\\text{Loss}_{OLS} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Ridge Regression modifies it:\n",
    "\n",
    "$$\n",
    "\\text{Loss}_{Ridge} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\lambda$ = regularization strength (hyperparameter).\n",
    "* $\\beta_j^2$ = squared coefficients (L2 penalty).\n",
    "* Intercept ($\\beta_0$) is not penalized.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Effect of L2 Penalty**\n",
    "\n",
    "* **If Î» = 0** â†’ Ridge = OLS (no shrinkage).\n",
    "* **If Î» is small** â†’ coefficients shrink slightly.\n",
    "* **If Î» is large** â†’ coefficients shrink strongly but never reach exactly zero.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Why Ridge Never Zeros Out Coefficients**\n",
    "\n",
    "The L2 penalty creates a **circular/elliptical constraint region**.\n",
    "\n",
    "* Optimization prefers to **spread weights across features** instead of eliminating them.\n",
    "* So, Ridge is good when **all features contribute a little**.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. When to Use Ridge**\n",
    "\n",
    "âœ… When you have **multicollinearity** (features are correlated).\n",
    "âœ… When you donâ€™t want to remove features but want to **reduce variance**.\n",
    "âœ… Works best when many features have **small to medium influence**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Visual Intuition**\n",
    "\n",
    "* Ridge forces coefficients to lie inside a **circle (or sphere in higher dimensions)**.\n",
    "* Because circles have no sharp corners, coefficients get shrunk smoothly, never exactly zero.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Example in Python**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([3, 4, 5, 6])\n",
    "\n",
    "# Ridge model\n",
    "model = Ridge(alpha=1.0)  # alpha = Î»\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ”‘ **Key difference vs Lasso (L1):**\n",
    "\n",
    "* Ridge shrinks coefficients continuously but **keeps all features**.\n",
    "* Lasso can shrink some coefficients to **exactly zero â†’ feature selection**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d5e2c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata