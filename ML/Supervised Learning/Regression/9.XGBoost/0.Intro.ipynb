{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7bd1c2",
   "metadata": {},
   "source": [
    "### Core Idea\n",
    "\n",
    "* Build many **weak learners (decision trees)** sequentially.\n",
    "* Each new tree tries to correct errors made by previous trees.\n",
    "* Uses **gradient descent** on a loss function to optimize.\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. **Initialize model** with a simple prediction (e.g., mean of target for regression, log-odds for classification).\n",
    "2. **Compute gradients (residuals):** Errors between prediction and actual.\n",
    "3. **Fit decision tree** to these residuals.\n",
    "4. **Update prediction:** Add weighted tree outputs to previous prediction.\n",
    "5. **Repeat** steps until reaching max trees or convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "XGBoost minimizes:\n",
    "\n",
    "$$\n",
    "Obj = \\sum_i l(y_i, \\hat{y}_i) + \\sum_k \\Omega(f_k)\n",
    "$$\n",
    "\n",
    "* $l$: loss function (e.g., log loss for classification, MSE for regression)\n",
    "* $\\Omega$: regularization term = prevents overfitting by penalizing complex trees\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "\n",
    "* **Regularization (L1 + L2)** → controls overfitting.\n",
    "* **Parallel tree construction** → faster training than standard GBM.\n",
    "* **Handling missing values** automatically.\n",
    "* **Tree pruning** (stops splitting if gain < threshold).\n",
    "* **Learning rate (η)** → scales contribution of each tree.\n",
    "* **Early stopping** → halts training when no improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### Important Hyperparameters\n",
    "\n",
    "* `n_estimators` → number of trees\n",
    "* `max_depth` → tree depth\n",
    "* `learning_rate` → shrinkage factor\n",
    "* `subsample` → fraction of rows per tree\n",
    "* `colsample_bytree` → fraction of features per tree\n",
    "* `lambda`, `alpha` → L2 and L1 regularization\n",
    "\n",
    "---\n",
    "\n",
    "### Example Use Cases\n",
    "\n",
    "* Classification: spam detection, fraud detection, churn prediction\n",
    "* Regression: house prices, demand forecasting\n",
    "* Ranking: recommender systems, search ranking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d195e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
