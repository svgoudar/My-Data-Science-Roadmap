{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bd46f0",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ”¹ Eigen Decomposition\n",
    "\n",
    "### Definition:\n",
    "\n",
    "Eigen decomposition is a way to break down a **square matrix** $A \\in \\mathbb{R}^{n \\times n}$ into its **eigenvectors** and **eigenvalues**.\n",
    "\n",
    "We look for vectors $v$ (non-zero) and scalars $\\lambda$ such that:\n",
    "\n",
    "$$\n",
    "A v = \\lambda v\n",
    "$$\n",
    "\n",
    "* $v$ â†’ **eigenvector** (direction unchanged by $A$)\n",
    "* $\\lambda$ â†’ **eigenvalue** (amount of stretching/shrinking along $v$)\n",
    "\n",
    "---\n",
    "\n",
    "### Matrix form:\n",
    "\n",
    "If $A$ has $n$ linearly independent eigenvectors:\n",
    "\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "* $V$: matrix of eigenvectors\n",
    "* $\\Lambda$: diagonal matrix of eigenvalues\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Example intuition**:\n",
    "Imagine $A$ is a transformation (like a stretch/rotation).\n",
    "\n",
    "* Eigenvectors are the special directions where transformation just **scales** (no rotation).\n",
    "* Eigenvalues are how much scaling happens.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ”¹ Singular Value Decomposition (SVD)\n",
    "\n",
    "### Definition:\n",
    "\n",
    "SVD is a **general decomposition** that works for **any** $m \\times n$ matrix (square or rectangular).\n",
    "\n",
    "For matrix $A \\in \\mathbb{R}^{m \\times n}$:\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "* $U \\in \\mathbb{R}^{m \\times m}$: orthogonal (left singular vectors)\n",
    "* $\\Sigma \\in \\mathbb{R}^{m \\times n}$: diagonal with **singular values** (non-negative, sorted)\n",
    "* $V \\in \\mathbb{R}^{n \\times n}$: orthogonal (right singular vectors)\n",
    "\n",
    "---\n",
    "\n",
    "### Intuition:\n",
    "\n",
    "* $V$: gives directions in input space (features).\n",
    "* $U$: gives directions in output space.\n",
    "* $\\Sigma$: tells how much scaling happens along each direction.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Applications of SVD**:\n",
    "\n",
    "* Dimensionality reduction (PCA uses it).\n",
    "* Image compression.\n",
    "* Recommender systems (matrix factorization).\n",
    "* Noise reduction.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ”¹ Relation between Eigen Decomposition and SVD\n",
    "\n",
    "* If $A$ is **symmetric** ($A = A^T$):\n",
    "\n",
    "  * Eigen decomposition: $A = V \\Lambda V^T$.\n",
    "  * SVD: $A = U \\Sigma V^T$ with $U = V$, $\\Sigma = |\\Lambda|$.\n",
    "\n",
    "* In **PCA**:\n",
    "\n",
    "  * You can either do eigen decomposition of covariance matrix $C = X^T X$,\n",
    "  * Or do SVD directly on $X$. Both give the same principal components.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ”‘ Key Difference:\n",
    "\n",
    "| Aspect      | Eigen Decomposition                   | SVD                                   |\n",
    "| ----------- | ------------------------------------- | ------------------------------------- |\n",
    "| Works on    | Only **square** matrices              | Any $m \\times n$ matrix               |\n",
    "| Values      | Eigenvalues (can be negative/complex) | Singular values (always non-negative) |\n",
    "| Use in ML   | PCA, spectral clustering              | PCA, recommender systems, compression |\n",
    "| Requirement | Matrix must be diagonalizable         | Always possible                       |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
